{   
    "do_train": true,
    "evaluate_during_training": true,
    "data_dir": "datasets",
    "train_yaml": "MSRVTT-v2/train_32frames.yaml",
    "val_yaml": "MSRVTT-v2/val_32frames.yaml",
    "do_lower_case": true,
    "max_seq_a_length": 50,
    "max_seq_length": 50,
    "max_img_seq_length": 196,
    "img_res": 224,
    "max_num_frames": 8,
    "patch_size": 32,
    "per_gpu_eval_batch_size": 4,
    "per_gpu_train_batch_size": 4,
    "num_workers": 4,
    "model_name_or_path": "models/captioning/bert-base-uncased/",
    "pretrained_checkpoint": "",
    "output_dir": "output/local_debug",
    "img_feature_dim": 512,
    "vidswin_size": "base",
    "kinetics": "600",
    "use_clip_model": true,
    "pretrained_2d": false,
    "grid_feat": true,
    "mask_prob": 0.15,
    "max_masked_tokens": 3,
    "attn_mask_type": "seq2seq",
    "max_gen_length": 20,
    "on_memory": false,
    "use_checkpoint": true,
    "num_train_epochs": 1,
    "learning_rate": 0.00015,
    "backbone_coef_lr": 0.01,
    "scheduler": "warmup_linear",
    "warmup_ratio": 0.1,
    "weight_decay": 0.05,
    "max_grad_norm": 1.0,
    "gradient_accumulation_steps": 4,
    "mixed_precision_method": "apex",
    "amp_opt_level": 2,
    "deepspeed_fp16": false,
    "fairscale_fp16": false,
    "zero_opt_stage": -1,
    "debug": false,
    "seed": 88
} 